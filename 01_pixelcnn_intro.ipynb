{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PixelCNN: Introduction and Tutorial\n",
        "\n",
        "This notebook introduces PixelCNN step by step. Goal: a **physically and mathematically\n",
        "accurate** explanation **and** a runnable reference implementation.\n",
        "\n",
        "**Learning goals**\n",
        "- Why autoregressive models provide exact likelihoods\n",
        "- How masked convolutions enforce causality in images\n",
        "- How training (negative log-likelihood) and sampling work\n",
        "- Physical context: relation to entropy and statistical mechanics\n",
        "\n",
        "**Runtime note**: The training cells are intentionally small. For better samples later,\n",
        "use more epochs or a larger model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n",
        "We use PyTorch and train on MNIST (28x28 grayscale).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Imports and reproducibility\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Theory: Autoregressive Modeling\n",
        "An image is treated as a vector of pixels \\(x = (x_1, x_2, ..., x_N)\\).\n",
        "By the chain rule, any distribution can be written as a product of conditional\n",
        "probabilities:\n",
        "\n",
        "\\[\n",
        "p(x) = \\prod_{i=1}^{N} p(x_i \\mid x_{<i})\n",
        "\\]\n",
        "\n",
        "For images we choose a raster ordering (e.g., row-wise). The model must therefore\n",
        "predict each pixel given all previous pixels.\n",
        "\n",
        "**Training**: Maximizing the log-likelihood is equivalent to minimizing the negative\n",
        "log-likelihood (NLL):\n",
        "\n",
        "\\[\n",
        "\\mathcal{L} = - \\sum_{i=1}^{N} \\log p(x_i \\mid x_{<i})\n",
        "\\]\n",
        "\n",
        "Because the likelihood is exactly computable, we can report *exact* log-likelihoods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. PixelCNN Idea: Masked Convolutions\n",
        "A standard convolution uses neighbors in all directions. That would allow the model\n",
        "to see **future** pixels when predicting \\(x_i\\). PixelCNN prevents this via **masked\n",
        "convolutions**:\n",
        "\n",
        "- **Mask A**: for the first layer (the current pixel itself is not allowed)\n",
        "- **Mask B**: for later layers (current pixel allowed, but no future pixels)\n",
        "\n",
        "This preserves autoregressive causality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualize Mask A/B\n",
        "def make_mask(kernel_size, mask_type):\n",
        "    k = kernel_size\n",
        "    mask = np.ones((k, k), dtype=np.float32)\n",
        "    center = k // 2\n",
        "    for i in range(k):\n",
        "        for j in range(k):\n",
        "            if i > center or (i == center and j > center):\n",
        "                mask[i, j] = 0.0\n",
        "    if mask_type == 'A':\n",
        "        mask[center, center] = 0.0\n",
        "    return mask\n",
        "\n",
        "maskA = make_mask(5, 'A')\n",
        "maskB = make_mask(5, 'B')\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
        "ax[0].imshow(maskA, cmap='gray', vmin=0, vmax=1)\n",
        "ax[0].set_title('Mask A')\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(maskB, cmap='gray', vmin=0, vmax=1)\n",
        "ax[1].set_title('Mask B')\n",
        "ax[1].axis('off')\n",
        "plt.tight_layout()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Implementation: MaskedConv2d and PixelCNN\n",
        "We build a simple PixelCNN variant (no gating/ResNet) that shows the idea correctly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class MaskedConv2d(nn.Conv2d):\n",
        "    def __init__(self, mask_type, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        assert mask_type in ('A', 'B')\n",
        "        self.mask_type = mask_type\n",
        "        self.register_buffer('mask', torch.ones_like(self.weight))\n",
        "        self._create_mask()\n",
        "\n",
        "    def _create_mask(self):\n",
        "        kH, kW = self.kernel_size\n",
        "        center_h = kH // 2\n",
        "        center_w = kW // 2\n",
        "        self.mask[:, :, center_h+1:, :] = 0\n",
        "        self.mask[:, :, center_h, center_w+1:] = 0\n",
        "        if self.mask_type == 'A':\n",
        "            self.mask[:, :, center_h, center_w] = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Enforce causality via mask without in-place weight edits\n",
        "        return F.conv2d(\n",
        "            x,\n",
        "            self.weight * self.mask,\n",
        "            self.bias,\n",
        "            self.stride,\n",
        "            self.padding,\n",
        "            self.dilation,\n",
        "            self.groups,\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class SimplePixelCNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, n_filters=64, n_layers=7, n_bins=16):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        # First layer: Mask A\n",
        "        layers.append(MaskedConv2d('A', in_channels, n_filters, kernel_size=7, padding=3))\n",
        "        layers.append(nn.ReLU())\n",
        "        # Middle layers: Mask B\n",
        "        for _ in range(n_layers - 2):\n",
        "            layers.append(MaskedConv2d('B', n_filters, n_filters, kernel_size=3, padding=1))\n",
        "            layers.append(nn.ReLU())\n",
        "        # Output: n_bins logits per pixel\n",
        "        layers.append(MaskedConv2d('B', n_filters, n_bins, kernel_size=1))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Output: [B, n_bins, H, W]\n",
        "        return self.net(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data: MNIST and Quantization\n",
        "PixelCNN models **discrete** values. We quantize grayscale values into `n_bins`\n",
        "classes (e.g., 16).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Parameters\n",
        "n_bins = 16\n",
        "batch_size = 64\n",
        "\n",
        "# Load MNIST\n",
        "transform = transforms.ToTensor()\n",
        "train_ds = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_ds = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Use a subset for faster training\n",
        "train_subset = Subset(train_ds, list(range(0, 5000)))\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "def quantize(x, n_bins):\n",
        "    # x in [0,1] -> integer in [0, n_bins-1]\n",
        "    x = torch.clamp(x, 0, 1)\n",
        "    return (x * (n_bins - 1)).round().long()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training\n",
        "We optimize the negative log-likelihood, which for discrete pixels is just\n",
        "cross-entropy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = SimplePixelCNN(in_channels=1, n_filters=64, n_layers=7, n_bins=n_bins).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def train_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for x, _ in loader:\n",
        "        x = x.to(device)\n",
        "        xq = quantize(x, n_bins)  # [B,1,H,W] int\n",
        "        logits = model(x)        # [B,n_bins,H,W]\n",
        "        loss = F.cross_entropy(logits, xq.squeeze(1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "epochs = 2  # small for demo\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train_epoch(model, train_loader)\n",
        "    print('Epoch {}: loss = {:.4f}'.format(epoch, loss))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sampling (Generative Model)\n",
        "During sampling we build an image pixel by pixel. For each pixel we compute\n",
        "\\(p(x_i \\mid x_{<i})\\) and draw a sample from that distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def sample(model, n_samples=16, shape=(1, 28, 28), n_bins=16):\n",
        "    model.eval()\n",
        "    C, H, W = shape\n",
        "    x = torch.zeros((n_samples, C, H, W), device=device)\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            logits = model(x)\n",
        "            probs = F.softmax(logits[:, :, i, j], dim=1)\n",
        "            sample_ij = torch.multinomial(probs, num_samples=1)\n",
        "            # Rescale back to [0,1]\n",
        "            x[:, :, i, j] = sample_ij.float() / (n_bins - 1)\n",
        "    return x\n",
        "\n",
        "samples = sample(model, n_samples=16, shape=(1, 28, 28), n_bins=n_bins)\n",
        "samples = samples.cpu().numpy()\n",
        "\n",
        "fig, ax = plt.subplots(4, 4, figsize=(6, 6))\n",
        "for i in range(16):\n",
        "    ax[i//4, i%4].imshow(samples[i, 0], cmap='gray')\n",
        "    ax[i//4, i%4].axis('off')\n",
        "plt.tight_layout()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Physical Context\n",
        "PixelCNN can be viewed as a probabilistic model on a lattice. In statistical mechanics,\n",
        "configurations \\(x\\) are often described by a Boltzmann distribution\n",
        "\\(p(x) \\propto \\exp(-E(x)/T)\\). The main difficulty there is the **partition function**\n",
        "(normalization), which is usually hard to compute.\n",
        "\n",
        "In the autoregressive approach, normalization is trivial because \\(p(x)\\) is explicitly\n",
        "constructed as a product of conditionals. This implies:\n",
        "- Exact log-likelihood (no approximation of the normalization)\n",
        "- Exact model entropy via the NLL\n",
        "\n",
        "Therefore PixelCNN is physically interesting when you need **exact** probabilities on\n",
        "lattice configurations, e.g., for classical spin models or as a comparison to\n",
        "energy-based models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Outlook and Extensions\n",
        "- **Gated PixelCNN**: better modeling via gating and ResNet-style blocks\n",
        "- **Conditional PixelCNN**: conditioning on labels or other fields\n",
        "- **PixelCNN++**: logistic mixtures for continuous values\n",
        "\n",
        "If you want, we can implement one of these variants next or adapt the model to a\n",
        "physical lattice dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Exercises (optional)\n",
        "1. Increase `n_bins` and observe sample quality.\n",
        "2. Train for more epochs and compare log-likelihood.\n",
        "3. Implement residual blocks or Gated PixelCNN.\n",
        "4. Test the model on a physical spin lattice.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}